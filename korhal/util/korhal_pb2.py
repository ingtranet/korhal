# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: korhal.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='korhal.proto',
  package='korhal',
  syntax='proto3',
  serialized_options=_b('\n\021net.ingtra.korhalB\013KorhalProtoP\001\242\002\006KORHAL'),
  serialized_pb=_b('\n\x0ckorhal.proto\x12\x06korhal\"<\n\x0bTextRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x11\n\ttokenizer\x18\x02 \x01(\t\x12\x0c\n\x04\x61rgs\x18\x03 \x03(\t\"p\n\x0eTokensResponse\x12,\n\x06tokens\x18\x01 \x03(\x0b\x32\x1c.korhal.TokensResponse.Token\x1a\x30\n\x05Token\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x0b\n\x03pos\x18\x02 \x01(\t\x12\x0c\n\x04misc\x18\x03 \x01(\t\"\x1e\n\rTextsResponse\x12\r\n\x05texts\x18\x01 \x03(\t2\x85\x01\n\tTokenizer\x12\x39\n\x08Tokenize\x12\x13.korhal.TextRequest\x1a\x16.korhal.TokensResponse\"\x00\x12=\n\rSplitSentence\x12\x13.korhal.TextRequest\x1a\x15.korhal.TextsResponse\"\x00\x42+\n\x11net.ingtra.korhalB\x0bKorhalProtoP\x01\xa2\x02\x06KORHALb\x06proto3')
)




_TEXTREQUEST = _descriptor.Descriptor(
  name='TextRequest',
  full_name='korhal.TextRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='text', full_name='korhal.TextRequest.text', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='tokenizer', full_name='korhal.TextRequest.tokenizer', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='args', full_name='korhal.TextRequest.args', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=24,
  serialized_end=84,
)


_TOKENSRESPONSE_TOKEN = _descriptor.Descriptor(
  name='Token',
  full_name='korhal.TokensResponse.Token',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='text', full_name='korhal.TokensResponse.Token.text', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='pos', full_name='korhal.TokensResponse.Token.pos', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='misc', full_name='korhal.TokensResponse.Token.misc', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=150,
  serialized_end=198,
)

_TOKENSRESPONSE = _descriptor.Descriptor(
  name='TokensResponse',
  full_name='korhal.TokensResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='tokens', full_name='korhal.TokensResponse.tokens', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_TOKENSRESPONSE_TOKEN, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=86,
  serialized_end=198,
)


_TEXTSRESPONSE = _descriptor.Descriptor(
  name='TextsResponse',
  full_name='korhal.TextsResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='texts', full_name='korhal.TextsResponse.texts', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=200,
  serialized_end=230,
)

_TOKENSRESPONSE_TOKEN.containing_type = _TOKENSRESPONSE
_TOKENSRESPONSE.fields_by_name['tokens'].message_type = _TOKENSRESPONSE_TOKEN
DESCRIPTOR.message_types_by_name['TextRequest'] = _TEXTREQUEST
DESCRIPTOR.message_types_by_name['TokensResponse'] = _TOKENSRESPONSE
DESCRIPTOR.message_types_by_name['TextsResponse'] = _TEXTSRESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

TextRequest = _reflection.GeneratedProtocolMessageType('TextRequest', (_message.Message,), dict(
  DESCRIPTOR = _TEXTREQUEST,
  __module__ = 'korhal_pb2'
  # @@protoc_insertion_point(class_scope:korhal.TextRequest)
  ))
_sym_db.RegisterMessage(TextRequest)

TokensResponse = _reflection.GeneratedProtocolMessageType('TokensResponse', (_message.Message,), dict(

  Token = _reflection.GeneratedProtocolMessageType('Token', (_message.Message,), dict(
    DESCRIPTOR = _TOKENSRESPONSE_TOKEN,
    __module__ = 'korhal_pb2'
    # @@protoc_insertion_point(class_scope:korhal.TokensResponse.Token)
    ))
  ,
  DESCRIPTOR = _TOKENSRESPONSE,
  __module__ = 'korhal_pb2'
  # @@protoc_insertion_point(class_scope:korhal.TokensResponse)
  ))
_sym_db.RegisterMessage(TokensResponse)
_sym_db.RegisterMessage(TokensResponse.Token)

TextsResponse = _reflection.GeneratedProtocolMessageType('TextsResponse', (_message.Message,), dict(
  DESCRIPTOR = _TEXTSRESPONSE,
  __module__ = 'korhal_pb2'
  # @@protoc_insertion_point(class_scope:korhal.TextsResponse)
  ))
_sym_db.RegisterMessage(TextsResponse)


DESCRIPTOR._options = None

_TOKENIZER = _descriptor.ServiceDescriptor(
  name='Tokenizer',
  full_name='korhal.Tokenizer',
  file=DESCRIPTOR,
  index=0,
  serialized_options=None,
  serialized_start=233,
  serialized_end=366,
  methods=[
  _descriptor.MethodDescriptor(
    name='Tokenize',
    full_name='korhal.Tokenizer.Tokenize',
    index=0,
    containing_service=None,
    input_type=_TEXTREQUEST,
    output_type=_TOKENSRESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='SplitSentence',
    full_name='korhal.Tokenizer.SplitSentence',
    index=1,
    containing_service=None,
    input_type=_TEXTREQUEST,
    output_type=_TEXTSRESPONSE,
    serialized_options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_TOKENIZER)

DESCRIPTOR.services_by_name['Tokenizer'] = _TOKENIZER

# @@protoc_insertion_point(module_scope)
